{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9019eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3b4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the prototext and model paths\n",
    "from os.path import dirname, join\n",
    "protoPath = join('C:/Users/PROMIT/Desktop/DFT/AI_ML/', \"deploy.prototxt.txt\")\n",
    "modelPath = join('C:/Users/PROMIT/Desktop/DFT/AI_ML/', \"res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a578918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading face detection classifier\n",
    "face_detection_classifier=cv2.dnn.readNetFromCaffe(protoPath,modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3ff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    #Capture frame by frame\n",
    "    ret,image_to_detect=cap.read()\n",
    "    #Extracting dimensions of the image\n",
    "    img_height=image_to_detect.shape[0]\n",
    "    img_width=image_to_detect.shape[1]\n",
    "    #Resizing the image\n",
    "    resized_image=cv2.resize(image_to_detect,(300,300))\n",
    "    #create blob of the image\n",
    "    image_to_detect_blob=cv2.dnn.blobFromImage(resized_image,1.0,(300,300),(104.0,177.0,123.0))\n",
    "    #passing the blob as model input\n",
    "    face_detection_classifier.setInput(image_to_detect_blob)  \n",
    "    #detect all face loactions \n",
    "    all_face_locations=face_detection_classifier.forward()\n",
    "    # loop over the detections\n",
    "    for i in range(0,all_face_locations.shape[2]):\n",
    "        confidence = all_face_locations[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = all_face_locations[0, 0, i, 3:7] * np.array([img_width,img_height,img_width,img_height])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            \n",
    "            cv2.putText(image_to_detect, text, (startX, y),cv2.FONT_HERSHEY_TRIPLEX, 1.2, (255,204,2), 2)\n",
    "        cv2.rectangle(image_to_detect, (startX, startY), (endX, endY),(153, 255, 102), 2)    \n",
    "       # show the output image\n",
    "    cv2.namedWindow('Output', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Output',image_to_detect)\n",
    "    if cv2.waitKey(20)& 0xFF == ord('q'):\n",
    "        break\n",
    "#When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38518a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
